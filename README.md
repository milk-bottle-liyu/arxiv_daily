## Updated on 2024.08.15

## LLM4AD

|Publish Date|Title|Authors|PDF|Code|Finish|
|---|---|---|---|---|---|
|**2024-08-14**|**LLMI3D: Empowering LLM with 3D Perception from a Single 2D Image**|Fan Yang et.al.|[2408.07422v1](http://arxiv.org/abs/2408.07422v1)|null|**&cross;**|
|**2024-08-07**|**Leveraging LLMs for Enhanced Open-Vocabulary 3D Scene Understanding in Autonomous Driving**|Amirhosein Chahe et.al.|[2408.03516v1](http://arxiv.org/abs/2408.03516v1)|null|**&cross;**|
|**2024-08-06**|**Compromising Embodied Agents with Contextual Backdoor Attacks**|Aishan Liu et.al.|[2408.02882v1](http://arxiv.org/abs/2408.02882v1)|null|**&cross;**|
|**2024-07-31**|**SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**|Peiru Zheng et.al.|[2407.21293v1](http://arxiv.org/abs/2407.21293v1)|null|**&cross;**|
|**2024-07-27**|**Large Language Models for Human-like Autonomous Driving: A Survey**|Yun Li et.al.|[2407.19280v1](http://arxiv.org/abs/2407.19280v1)|null|**&cross;**|
|**2024-07-26**|**Wolf: Captioning Everything with a World Summarization Framework**|Boyi Li et.al.|[2407.18908v1](http://arxiv.org/abs/2407.18908v1)|null|**&cross;**|
|**2024-07-24**|**3D Question Answering for City Scene Understanding**|Penglei Sun et.al.|[2407.17398v1](http://arxiv.org/abs/2407.17398v1)|null|**&cross;**|
|**2024-07-24**|**Testing Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles**|Zuoyin Tang et.al.|[2407.17211v1](http://arxiv.org/abs/2407.17211v1)|null|**&cross;**|
|**2024-07-26**|**When, Where, and What? A Novel Benchmark for Accident Anticipation and Localization with Large Language Models**|Haicheng Liao et.al.|[2407.16277v2](http://arxiv.org/abs/2407.16277v2)|null|**&cross;**|
|**2024-07-22**|**WTS: A Pedestrian-Centric Traffic Video Dataset for Fine-grained Spatial-Temporal Understanding**|Quan Kong et.al.|[2407.15350v1](http://arxiv.org/abs/2407.15350v1)|null|**&cross;**|
|**2024-07-19**|**KoMA: Knowledge-driven Multi-agent Framework for Autonomous Driving with Large Language Models**|Kemou Jiang et.al.|[2407.14239v1](http://arxiv.org/abs/2407.14239v1)|null|**&cross;**|
|**2024-07-17**|**AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases**|Zhaorun Chen et.al.|[2407.12784v1](http://arxiv.org/abs/2407.12784v1)|**[link](https://github.com/BillChan226/AgentPoison)**|**&cross;**|
|**2024-07-14**|**Follow the Rules: Reasoning for Video Anomaly Detection with Large Language Models**|Yuchen Yang et.al.|[2407.10299v1](http://arxiv.org/abs/2407.10299v1)|**[link](https://github.com/Yuchen413/AnomalyRuler)**|**&cross;**|
|**2024-07-08**|**GenFollower: Enhancing Car-Following Prediction with Large Language Models**|Xianda Chen et.al.|[2407.05611v1](http://arxiv.org/abs/2407.05611v1)|null|**&cross;**|
|**2024-07-05**|**WOMD-Reasoning: A Large-Scale Language Dataset for Interaction and Driving Intentions Reasoning**|Yiheng Li et.al.|[2407.04281v1](http://arxiv.org/abs/2407.04281v1)|null|**&cross;**|
|**2024-07-01**|**Data on the Move: Traffic-Oriented Data Trading Platform Powered by AI Agent with Common Sense**|Yi Yu et.al.|[2407.00995v1](http://arxiv.org/abs/2407.00995v1)|null|**&cross;**|
|**2024-07-01**|**Tokenize the World into Object-level Knowledge to Address Long-tail Events in Autonomous Driving**|Ran Tian et.al.|[2407.00959v1](http://arxiv.org/abs/2407.00959v1)|null|**&cross;**|
|**2024-06-21**|**Asynchronous Large Language Model Enhanced Planner for Autonomous Driving**|Yuan Chen et.al.|[2406.14556v2](http://arxiv.org/abs/2406.14556v2)|null|**&cross;**|
|**2024-06-16**|**An LLM-enhanced Multi-objective Evolutionary Search for Autonomous Driving Test Scenario Generation**|Haoxiang Tian et.al.|[2406.10857v1](http://arxiv.org/abs/2406.10857v1)|null|**&cross;**|
|**2024-06-15**|**Generating and Evolving Reward Functions for Highway Driving with Large Language Models**|Xu Han et.al.|[2406.10540v1](http://arxiv.org/abs/2406.10540v1)|null|**&cross;**|
|**2024-06-11**|**Instruct Large Language Models to Drive like Humans**|Ruijun Zhang et.al.|[2406.07296v1](http://arxiv.org/abs/2406.07296v1)|**[link](https://github.com/bonbon-rj/instructdriver)**|**&cross;**|
|**2024-06-09**|**A Superalignment Framework in Autonomous Driving with Large Language Models**|Xiangrui Kong et.al.|[2406.05651v1](http://arxiv.org/abs/2406.05651v1)|null|**&cross;**|
|**2024-06-07**|**CityCraft: A Real Crafter for 3D City Generation**|Jie Deng et.al.|[2406.04983v1](http://arxiv.org/abs/2406.04983v1)|null|**&cross;**|
|**2024-06-06**|**Optimizing Autonomous Driving for Safety: A Human-Centric Approach with LLM-Enhanced RLHF**|Yuan Sun et.al.|[2406.04481v1](http://arxiv.org/abs/2406.04481v1)|null|**&cross;**|
|**2024-06-05**|**DriVLMe: Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences**|Yidong Huang et.al.|[2406.03008v1](http://arxiv.org/abs/2406.03008v1)|null|**&cross;**|
|**2024-06-03**|**REvolve: Reward Evolution with Large Language Models for Autonomous Driving**|Rishi Hazra et.al.|[2406.01309v1](http://arxiv.org/abs/2406.01309v1)|null|**&cross;**|
|**2024-05-29**|**Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language Models**|Tianrun Chen et.al.|[2405.19326v1](http://arxiv.org/abs/2405.19326v1)|null|**&cross;**|
|**2024-05-28**|**Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving?**|Yifan Bai et.al.|[2405.18361v1](http://arxiv.org/abs/2405.18361v1)|null|**&cross;**|
|**2024-05-23**|**Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving with Typography**|Nhat Chung et.al.|[2405.14169v1](http://arxiv.org/abs/2405.14169v1)|null|**&cross;**|
|**2024-05-22**|**ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles**|Jiawei Zhang et.al.|[2405.14062v1](http://arxiv.org/abs/2405.14062v1)|**[link](https://github.com/javyduck/ChatScene)**|**&cross;**|
|**2024-05-22**|**HighwayLLM: Decision-Making and Navigation in Highway Driving with RL-Informed Language Model**|Mustafa Yildirim et.al.|[2405.13547v1](http://arxiv.org/abs/2405.13547v1)|null|**&cross;**|
|**2024-05-12**|**Large Language Models for Education: A Survey**|Hanyi Xu et.al.|[2405.13001v1](http://arxiv.org/abs/2405.13001v1)|null|**&cross;**|
|**2024-03-06**|**Levels of AI Agents: from Rules to Large Language Models**|Yu Huang et.al.|[2405.06643v1](http://arxiv.org/abs/2405.06643v1)|null|**&cross;**|
|**2024-05-09**|**Probing Multimodal LLMs as World Models for Driving**|Shiva Sreeram et.al.|[2405.05956v1](http://arxiv.org/abs/2405.05956v1)|**[link](https://github.com/sreeramsa/drivesim)**|**&cross;**|
|**2024-05-08**|**Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models**|Zhengxing Lan et.al.|[2405.04909v1](http://arxiv.org/abs/2405.04909v1)|null|**&cross;**|
|**2024-05-02**|**OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning**|Shihao Wang et.al.|[2405.01533v1](http://arxiv.org/abs/2405.01533v1)|**[link](https://github.com/nvlabs/omnidrive)**|**&cross;**|
|**2024-05-01**|**RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models**|Mohamed Manzour Hussien et.al.|[2405.00449v1](http://arxiv.org/abs/2405.00449v1)|null|**&cross;**|
|**2024-05-05**|**How do LLMs Support Deep Learning Testing? A Comprehensive Study Through the Lens of Image Mutation**|Liwen Wang et.al.|[2404.13945v2](http://arxiv.org/abs/2404.13945v2)|null|**&cross;**|
|**2024-04-11**|**Can Vehicle Motion Planning Generalize to Realistic Long-tail Scenarios?**|Marcel Hallgarten et.al.|[2404.07569v1](http://arxiv.org/abs/2404.07569v1)|**[link](https://github.com/mh0797/interplan)**|**&cross;**|
|**2024-04-21**|**AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning**|Senkang Hu et.al.|[2404.06345v2](http://arxiv.org/abs/2404.06345v2)|null|**&cross;**|
|**2024-04-07**|**Prompting Multi-Modal Tokens to Enhance End-to-End Autonomous Driving Imitation Learning with LLMs**|Yiqun Duan et.al.|[2404.04869v1](http://arxiv.org/abs/2404.04869v1)|null|**&cross;**|
|**2024-05-09**|**Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving**|Akshay Gopalkrishnan et.al.|[2403.19838v2](http://arxiv.org/abs/2403.19838v2)|**[link](https://github.com/akshaygopalkr/em-vlm4ad)**|**&cross;**|
|**2024-03-24**|**Engineering Safety Requirements for Autonomous Driving with Large Language Models**|Ali Nouri et.al.|[2403.16289v1](http://arxiv.org/abs/2403.16289v1)|null|**&cross;**|
|**2024-03-17**|**Driving Style Alignment for LLM-powered Driver Agent**|Ruoxuan Yang et.al.|[2403.11368v1](http://arxiv.org/abs/2403.11368v1)|**[link](https://github.com/air-discover/driving-thinking-dataset)**|**&cross;**|
|**2024-03-17**|**Large Language Models Powered Context-aware Motion Prediction**|Xiaoji Zheng et.al.|[2403.11057v1](http://arxiv.org/abs/2403.11057v1)|null|**&cross;**|
|**2024-07-19**|**Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning**|Hang Zhang et.al.|[2403.10107v2](http://arxiv.org/abs/2403.10107v2)|null|**&cross;**|
|**2024-03-14**|**Reality Bites: Assessing the Realism of Driving Scenarios with Large Language Models**|Jiahui Wu et.al.|[2403.09906v1](http://arxiv.org/abs/2403.09906v1)|**[link](https://github.com/simula-complex/realitybites)**|**&cross;**|
|**2024-04-11**|**DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation**|Guosheng Zhao et.al.|[2403.06845v2](http://arxiv.org/abs/2403.06845v2)|null|**&cross;**|
|**2024-03-18**|**Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving**|Mehdi Azarafza et.al.|[2402.13602v3](http://arxiv.org/abs/2402.13602v3)|**[link](https://github.com/mehdiazarafza/hybrid-reasoning)**|**&cross;**|
|**2024-02-14**|**How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?**|Congcong Wen et.al.|[2402.09546v1](http://arxiv.org/abs/2402.09546v1)|null|**&cross;**|
|**2024-07-16**|**Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following**|Brian Yang et.al.|[2402.06559v2](http://arxiv.org/abs/2402.06559v2)|null|**&cross;**|
|**2024-04-10**|**Driving Everywhere with Large Language Model Policy Adaptation**|Boyi Li et.al.|[2402.05932v2](http://arxiv.org/abs/2402.05932v2)|null|**&cross;**|
|**2024-06-26**|**Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents**|Yuxi Wei et.al.|[2402.05746v3](http://arxiv.org/abs/2402.05746v3)|**[link](https://github.com/yifanlu0227/chatsim)**|**&cross;**|
|**2024-02-03**|**A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions**|Hung Du et.al.|[2402.01968v1](http://arxiv.org/abs/2402.01968v1)|null|**&cross;**|
|**2024-04-12**|**LimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving**|Daocheng Fu et.al.|[2402.01246v2](http://arxiv.org/abs/2402.01246v2)|null|**&cross;**|
|**2024-05-03**|**LangProp: A code optimization framework using Large Language Models applied to driving**|Shu Ishida et.al.|[2401.10314v2](http://arxiv.org/abs/2401.10314v2)|**[link](https://github.com/shuishida/langprop)**|**&cross;**|
|**2024-06-18**|**BEV-TSR: Text-Scene Retrieval in BEV Space for Autonomous Driving**|Tao Tang et.al.|[2401.01065v2](http://arxiv.org/abs/2401.01065v2)|null|**&cross;**|
|**2023-12-30**|**LLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning**|S P Sharan et.al.|[2401.00125v1](http://arxiv.org/abs/2401.00125v1)|null|**&cross;**|
|**2023-12-15**|**Neurosymbolic Value-Inspired AI (Why, What, and How)**|Amit Sheth et.al.|[2312.09928v1](http://arxiv.org/abs/2312.09928v1)|null|**&cross;**|
|**2024-05-08**|**Personalized Autonomous Driving with Large Language Models: Field Experiments**|Can Cui et.al.|[2312.09397v3](http://arxiv.org/abs/2312.09397v3)|null|**&cross;**|
|**2023-12-25**|**DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving**|Wenhai Wang et.al.|[2312.09245v2](http://arxiv.org/abs/2312.09245v2)|**[link](https://github.com/opengvlab/drivemlm)**|**&cross;**|
|**2023-12-21**|**LMDrive: Closed-Loop End-to-End Driving with Large Language Models**|Hao Shao et.al.|[2312.07488v2](http://arxiv.org/abs/2312.07488v2)|**[link](https://github.com/opendilab/lmdrive)**|**&cross;**|
|**2023-12-11**|**Evaluation of Large Language Models for Decision Making in Autonomous Driving**|Kotaro Tanahashi et.al.|[2312.06351v1](http://arxiv.org/abs/2312.06351v1)|null|**&cross;**|
|**2024-04-04**|**LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs**|Yunsheng Ma et.al.|[2312.04372v2](http://arxiv.org/abs/2312.04372v2)|**[link](https://github.com/purduedigitaltwin/lampilot)**|**&cross;**|
|**2023-12-06**|**GPT-4 Enhanced Multimodal Grounding for Autonomous Driving: Leveraging Cross-Modal Attention with Large Language Models**|Haicheng Liao et.al.|[2312.03543v1](http://arxiv.org/abs/2312.03543v1)|**[link](https://github.com/petrichor625/talk2car_cavg)**|**&cross;**|
|**2024-03-22**|**Empowering Autonomous Driving with Large Language Models: A Safety Perspective**|Yixuan Wang et.al.|[2312.00812v4](http://arxiv.org/abs/2312.00812v4)|null|**&cross;**|
|**2023-11-21**|**A Survey on Multimodal Large Language Models for Autonomous Driving**|Can Cui et.al.|[2311.12320v1](http://arxiv.org/abs/2311.12320v1)|**[link](https://github.com/irohxu/awesome-multimodal-llm-autonomous-driving)**|**&cross;**|
|**2024-01-05**|**Applications of Large Scale Foundation Models for Autonomous Driving**|Yu Huang et.al.|[2311.12144v7](http://arxiv.org/abs/2311.12144v7)|null|**&cross;**|
|**2023-11-20**|**Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems**|Guangjing Wang et.al.|[2311.11796v1](http://arxiv.org/abs/2311.11796v1)|null|**&cross;**|
|**2023-11-27**|**A Language Agent for Autonomous Driving**|Jiageng Mao et.al.|[2311.10813v3](http://arxiv.org/abs/2311.10813v3)|**[link](https://github.com/usc-gvl/agent-driver)**|**&cross;**|
|**2023-12-19**|**Human-Centric Autonomous Systems With LLMs for User Command Reasoning**|Yi Yang et.al.|[2311.08206v2](http://arxiv.org/abs/2311.08206v2)|**[link](https://github.com/kth-rpl/drivecmd_llm)**|**&cross;**|
|**2023-12-29**|**LLM4Drive: A Survey of Large Language Models for Autonomous Driving**|Zhenjie Yang et.al.|[2311.01043v3](http://arxiv.org/abs/2311.01043v3)|**[link](https://github.com/thinklab-sjtu/awesome-llm4ad)**|**&cross;**|
|**2023-11-01**|**Enhancing the Spatial Awareness Capability of Multi-Modal Large Language Model**|Yongqiang Zhao et.al.|[2310.20357v2](http://arxiv.org/abs/2310.20357v2)|null|**&cross;**|
|**2024-06-20**|**Vision Language Models in Autonomous Driving: A Survey and Outlook**|Xingcheng Zhou et.al.|[2310.14414v2](http://arxiv.org/abs/2310.14414v2)|**[link](https://github.com/ge25nab/Awesome-VLM-AD-ITS)**|**&cross;**|
|**2023-10-20**|**OpenAnnotate3D: Open-Vocabulary Auto-Labeling System for Multi-modal 3D Data**|Yijie Zhou et.al.|[2310.13398v1](http://arxiv.org/abs/2310.13398v1)|**[link](https://github.com/fudan-projecttitan/openannotate3d)**|**&cross;**|
|**2024-01-25**|**JM3D & JM3D-LLM: Elevating 3D Understanding with Joint Multi-modal Cues**|Jiayi Ji et.al.|[2310.09503v3](http://arxiv.org/abs/2310.09503v3)|**[link](https://github.com/mr-neko/jm3d)**|**&cross;**|
|**2023-10-12**|**Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles**|Can Cui et.al.|[2310.08034v1](http://arxiv.org/abs/2310.08034v1)|null|**&cross;**|
|**2023-10-13**|**LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving**|Hao Sha et.al.|[2310.03026v2](http://arxiv.org/abs/2310.03026v2)|null|**&cross;**|
|**2023-10-13**|**Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving**|Long Chen et.al.|[2310.01957v2](http://arxiv.org/abs/2310.01957v2)|**[link](https://github.com/wayveai/driving-with-llms)**|**&cross;**|
|**2023-12-05**|**GPT-Driver: Learning to Drive with GPT**|Jiageng Mao et.al.|[2310.01415v3](http://arxiv.org/abs/2310.01415v3)|**[link](https://github.com/pointscoder/gpt-driver)**|**&cross;**|
|**2024-03-14**|**DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model**|Zhenhua Xu et.al.|[2310.01412v4](http://arxiv.org/abs/2310.01412v4)|null|**&cross;**|
|**2024-02-22**|**DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models**|Licheng Wen et.al.|[2309.16292v3](http://arxiv.org/abs/2309.16292v3)|**[link](https://github.com/PJLab-ADG/DiLu)**|**&cross;**|
|**2023-09-22**|**SurrealDriver: Designing Generative Driver Agent Simulation Framework in Urban Contexts based on Large Language Model**|Ye Jin et.al.|[2309.13193v1](http://arxiv.org/abs/2309.13193v1)|null|**&cross;**|
|**2023-09-19**|**Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles**|Can Cui et.al.|[2309.10228v1](http://arxiv.org/abs/2309.10228v1)|null|**&cross;**|
|**2023-09-12**|**The Moral Machine Experiment on Large Language Models**|Kazuhiro Takemoto et.al.|[2309.05958v1](http://arxiv.org/abs/2309.05958v1)|**[link](https://github.com/kztakemoto/mmllm)**|**&cross;**|
|**2023-07-17**|**Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain**|Yun Tang et.al.|[2307.11769v1](http://arxiv.org/abs/2307.11769v1)|null|**&cross;**|
|**2023-07-14**|**Drive Like a Human: Rethinking Autonomous Driving with Large Language Models**|Daocheng Fu et.al.|[2307.07162v1](http://arxiv.org/abs/2307.07162v1)|**[link](https://github.com/PJLab-ADG/driveLikeAHuman)**|**&cross;**|
|**2023-05-24**|**DetGPT: Detect What You Need via Reasoning**|Renjie Pi et.al.|[2305.14167v2](http://arxiv.org/abs/2305.14167v2)|null|**&cross;**|
|**2023-09-11**|**Semantic Anomaly Detection with Large Language Models**|Amine Elhafsi et.al.|[2305.11307v2](http://arxiv.org/abs/2305.11307v2)|null|**&cross;**|
|**2023-06-02**|**ProgSG: Cross-Modality Representation Learning for Programs in Electronic Design Automation**|Yunsheng Bai et.al.|[2305.10838v2](http://arxiv.org/abs/2305.10838v2)|null|**&cross;**|

